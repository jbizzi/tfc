{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T23:25:40.377937400Z",
     "start_time": "2024-06-10T23:25:30.495450200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:25:37.000380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-10 20:25:37.000553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-10 20:25:37.017844: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-10 20:25:37.085915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 20:25:38.843432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run Datasets.ipynb\n",
    "import numpy as np\n",
    "from keras import Input, Model\n",
    "from keras.src.layers import Dense, BatchNormalization, GaussianNoise\n",
    "from src import HammingCode\n",
    "Eb_treinamento = 5.01187"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 3s 13ms/step - loss: 1.6654 - accuracy: 0.2125 - val_loss: 1.3881 - val_accuracy: 0.2670\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.4145 - accuracy: 0.3100 - val_loss: 1.3417 - val_accuracy: 0.2670\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.2206 - accuracy: 0.4645 - val_loss: 1.2966 - val_accuracy: 0.5030\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 1.0720 - accuracy: 0.5564 - val_loss: 1.2313 - val_accuracy: 0.7540\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.9353 - accuracy: 0.6584 - val_loss: 1.1426 - val_accuracy: 0.7540\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.7992 - accuracy: 0.8348 - val_loss: 1.0159 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.9488 - val_loss: 0.8675 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.9842 - val_loss: 0.7060 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.9957 - val_loss: 0.5411 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.9977 - val_loss: 0.3998 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2176 - accuracy: 0.9994 - val_loss: 0.2877 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1645 - accuracy: 0.9996 - val_loss: 0.2085 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.9997 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9995 - val_loss: 0.1071 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9999 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9998 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 2s 12ms/step - loss: 2.2820 - accuracy: 0.1783 - val_loss: 2.3092 - val_accuracy: 0.3820\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.6296 - accuracy: 0.5663 - val_loss: 2.1352 - val_accuracy: 0.4770\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.1509 - accuracy: 0.7656 - val_loss: 1.8885 - val_accuracy: 0.9150\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.8108 - accuracy: 0.8310 - val_loss: 1.6129 - val_accuracy: 0.9150\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.9096 - val_loss: 1.3275 - val_accuracy: 0.9150\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.9091 - val_loss: 1.0442 - val_accuracy: 0.9150\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.9235 - val_loss: 0.7801 - val_accuracy: 0.9150\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9697 - val_loss: 0.5513 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9969 - val_loss: 0.3717 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def create_autoencoder(code_rate, neurons, size, training_data, validation_data):\n",
    "    \n",
    "    entrada = Input(shape=(size,))\n",
    "    encoder1 = Dense(size, activation='relu')(entrada)\n",
    "    encoder2 = Dense(neurons, activation='linear')(encoder1)\n",
    "    encoder3 = BatchNormalization()(encoder2)\n",
    "    \n",
    "    \n",
    "    Eb_training = Eb_treinamento * code_rate\n",
    "    \n",
    "    noise = GaussianNoise(np.sqrt(1/(2* Eb_training)))(encoder3)\n",
    "    \n",
    "    decoder1 = Dense(size, activation='relu')(noise)\n",
    "    decoder2 = Dense(size, activation='softmax')(decoder1)\n",
    "    \n",
    "    autoencoder = Model(entrada, decoder2)\n",
    "    autoencoder.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    autoencoder.fit(\n",
    "    training_data,\n",
    "    training_data,\n",
    "    epochs=20,\n",
    "    batch_size=300,\n",
    "    validation_data=(validation_data, validation_data),\n",
    "    )\n",
    "\n",
    "    # Com o modelo treinado, separa em encoder e decoder\n",
    "    encoder = Model(entrada, encoder3)\n",
    "    \n",
    "    entrada_encoder = Input(shape=(neurons,))\n",
    "    decoder_layer1 = autoencoder.layers[-2](entrada_encoder)\n",
    "    decoder_layer2 = autoencoder.layers[-1](decoder_layer1)\n",
    "    decoder = Model(entrada_encoder, decoder_layer2)\n",
    "    \n",
    "    return encoder, decoder\n",
    "\n",
    "encoder, decoder = create_autoencoder(4/7, 7, 4, training_data, validation_data)\n",
    "encoder_11, decoder_11 =  create_autoencoder(11/15, 15, 11, training_data_11, validation_data_11)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T23:25:52.666385600Z",
     "start_time": "2024-06-10T23:25:40.387530400Z"
    }
   },
   "id": "ab025a96b6095514",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 2s 15ms/step - loss: 0.3280 - accuracy: 0.8611 - val_loss: 0.1471 - val_accuracy: 0.8880\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.8956 - val_loss: 0.1445 - val_accuracy: 0.8860\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1315 - accuracy: 0.8956 - val_loss: 0.1440 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1321 - accuracy: 0.8963 - val_loss: 0.1431 - val_accuracy: 0.8870\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.8959 - val_loss: 0.1443 - val_accuracy: 0.8780\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1315 - accuracy: 0.8953 - val_loss: 0.1445 - val_accuracy: 0.8890\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.8960 - val_loss: 0.1424 - val_accuracy: 0.8860\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1308 - accuracy: 0.8962 - val_loss: 0.1433 - val_accuracy: 0.8870\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.8977 - val_loss: 0.1433 - val_accuracy: 0.8840\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1299 - accuracy: 0.8965 - val_loss: 0.1443 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1302 - accuracy: 0.8968 - val_loss: 0.1455 - val_accuracy: 0.8860\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.8959 - val_loss: 0.1439 - val_accuracy: 0.8780\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1287 - accuracy: 0.8971 - val_loss: 0.1438 - val_accuracy: 0.8820\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.8968 - val_loss: 0.1418 - val_accuracy: 0.8850\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1293 - accuracy: 0.8977 - val_loss: 0.1443 - val_accuracy: 0.8830\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.8963 - val_loss: 0.1423 - val_accuracy: 0.8880\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1288 - accuracy: 0.8960 - val_loss: 0.1434 - val_accuracy: 0.8800\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1286 - accuracy: 0.8981 - val_loss: 0.1478 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1280 - accuracy: 0.8980 - val_loss: 0.1426 - val_accuracy: 0.8880\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1273 - accuracy: 0.8980 - val_loss: 0.1455 - val_accuracy: 0.8820\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.8820\n",
      "Loss: 0.14553304016590118\n",
      "Accuracy: 0.8820000290870667\n"
     ]
    }
   ],
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import Sequential\n",
    "\n",
    "# MLP\n",
    "noise_for_training = np.sqrt((1/(2*Eb_treinamento*(4/7)))) * np.random.randn(training_length, 4)    \n",
    "noisy_input_for_training = training_data + noise_for_training\n",
    "\n",
    "noise_for_validation = np.sqrt((1/(2*Eb_treinamento*(4/7)))) * np.random.randn(validation_length, 4)    \n",
    "\n",
    "noisy_input_for_validation = validation_data + noise_for_validation\n",
    "mlp = Sequential()\n",
    "mlp.add(Input(shape=(4,)))\n",
    "mlp.add(Dense(512, activation='relu'))\n",
    "mlp.add(Dense(256, activation='relu'))\n",
    "mlp.add(Dense(128, activation='relu'))\n",
    "mlp.add(Dense(4, activation='sigmoid'))\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp.fit(\n",
    "    noisy_input_for_training,\n",
    "    training_data,\n",
    "    epochs=20,\n",
    "    batch_size=300,\n",
    "    validation_data=(noisy_input_for_validation, validation_data),\n",
    ")\n",
    "\n",
    "loss, accuracy = mlp.evaluate(noisy_input_for_validation, validation_data)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T23:26:01.389363400Z",
     "start_time": "2024-06-10T23:25:52.666385600Z"
    }
   },
   "id": "407afa831c7233ed",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31250/31250 [==============================] - 60s 2ms/step\n",
      "31250/31250 [==============================] - 57s 2ms/step\n",
      "SNR  -4 BER  0.06977525\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "31250/31250 [==============================] - 67s 2ms/step\n",
      "SNR  -4 BER  0.015040727272727273\n",
      "SNR  -4 BER  0.26126575\n",
      "31250/31250 [==============================] - 77s 2ms/step\n",
      "SNR  -4 BER  0.27414425\n",
      "31250/31250 [==============================] - 73s 2ms/step\n",
      "31250/31250 [==============================] - 60s 2ms/step\n",
      "SNR  -3 BER  0.0517465\n",
      "31250/31250 [==============================] - 61s 2ms/step\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "SNR  -3 BER  0.008779\n",
      "SNR  -3 BER  0.2285005\n",
      "31250/31250 [==============================] - 78s 3ms/step\n",
      "SNR  -3 BER  0.2608715\n",
      "31250/31250 [==============================] - 61s 2ms/step\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "SNR  -2 BER  0.03611125\n",
      "31250/31250 [==============================] - 61s 2ms/step\n",
      "31250/31250 [==============================] - 63s 2ms/step\n",
      "SNR  -2 BER  0.004475\n",
      "SNR  -2 BER  0.1930565\n",
      "31250/31250 [==============================] - 75s 2ms/step\n",
      "SNR  -2 BER  0.24619475\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "31250/31250 [==============================] - 56s 2ms/step\n",
      "SNR  -1 BER  0.024151\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "31250/31250 [==============================] - 57s 2ms/step\n",
      "SNR  -1 BER  0.0019425454545454546\n",
      "SNR  -1 BER  0.15586275\n",
      "31250/31250 [==============================] - 74s 2ms/step\n",
      "SNR  -1 BER  0.22956275\n",
      "31250/31250 [==============================] - 59s 2ms/step\n",
      "31250/31250 [==============================] - 60s 2ms/step\n",
      "SNR  0 BER  0.01494525\n",
      "31250/31250 [==============================] - 60s 2ms/step\n",
      "31250/31250 [==============================] - 74s 2ms/step\n",
      "SNR  0 BER  0.0007038181818181819\n",
      "SNR  0 BER  0.11931925\n",
      "31250/31250 [==============================] - 91s 3ms/step\n",
      "SNR  0 BER  0.21143975\n",
      "31250/31250 [==============================] - 72s 2ms/step\n",
      "31250/31250 [==============================] - 61s 2ms/step\n",
      "SNR  1 BER  0.00869825\n",
      "31250/31250 [==============================] - 62s 2ms/step\n",
      "31250/31250 [==============================] - 58s 2ms/step\n",
      "SNR  1 BER  0.00020281818181818183\n",
      "SNR  1 BER  0.084737\n",
      "31250/31250 [==============================] - 82s 3ms/step\n",
      "SNR  1 BER  0.19168325\n",
      "31250/31250 [==============================] - 65s 2ms/step\n",
      "31250/31250 [==============================] - 60s 2ms/step\n",
      "SNR  2 BER  0.00469475\n",
      "31250/31250 [==============================] - 64s 2ms/step\n",
      "31250/31250 [==============================] - 61s 2ms/step\n",
      "SNR  2 BER  4.681818181818182e-05\n"
     ]
    }
   ],
   "source": [
    "from math import erfc\n",
    "\n",
    "Eb_dB_values = np.arange(-4, 11, 1)\n",
    "ber_autoencoder = []\n",
    "ber_Hamming = []\n",
    "ber_teorica = []\n",
    "ber_mlp = []\n",
    "ber_autoencoder_11 = []\n",
    "for i in range(0, len(Eb_dB_values)):\n",
    "    \n",
    "    \n",
    "    Eb = 10**(Eb_dB_values[i]/10)\n",
    "    \n",
    "    testing_data_autoencoder = copy.deepcopy(testing_data)\n",
    "    merged_sample = np.concatenate(testing_data_autoencoder)\n",
    "    \n",
    "    testing_data_hamming = copy.deepcopy(merged_sample)\n",
    "    testing_data_mlp = copy.deepcopy(testing_data)\n",
    "    merged_testing_data_mlp = copy.deepcopy(merged_sample)\n",
    "    noise = np.sqrt((1/(2*4/7*Eb))) * np.random.randn(test_length, 7)    \n",
    "    \n",
    "    noise_hamming = copy.deepcopy(noise)\n",
    "    noise_mlp = copy.deepcopy(noise)\n",
    "    \n",
    "    # codifica para 7 bits\n",
    "    codificado = encoder.predict(testing_data_autoencoder)\n",
    "    \n",
    "    #print(codificado)\n",
    "    # add ruido\n",
    "    codificado_com_ruido = codificado + noise\n",
    "    \n",
    "    #corrige com o decoder\n",
    "    corrigido = decoder.predict(codificado_com_ruido)\n",
    "    corrigido_merged = np.concatenate(corrigido)\n",
    "    corrigido_merged_digital = [1 if bit > 0.5 else 0 for bit in corrigido_merged]\n",
    "    calculated_ber = np.sum(np.array(corrigido_merged_digital).astype(int) != merged_sample.astype(int)) / len(merged_sample)\n",
    "    ber_autoencoder.append(calculated_ber)\n",
    "    print('SNR ', Eb_dB_values[i], 'BER ', calculated_ber)\n",
    "\n",
    "\n",
    "    ####################### Autoencoder 11\n",
    "    \n",
    "    testing_data_autoencoder_11 = copy.deepcopy(testing_data_11)\n",
    "    merged_sample_11 = np.concatenate(testing_data_autoencoder_11)\n",
    "    \n",
    "    noise_11 = np.sqrt((1/(2*11/15*Eb))) * np.random.randn(test_length, 15)    \n",
    "    \n",
    "    # codifica para 11 bits\n",
    "    codificado_11 = encoder_11.predict(testing_data_autoencoder_11)\n",
    "    \n",
    "    # add ruido\n",
    "    codificado_com_ruido_11 = codificado_11 + noise_11\n",
    "    \n",
    "    #corrige com o decoder\n",
    "    corrigido_11 = decoder_11.predict(codificado_com_ruido_11)\n",
    "    corrigido_merged_11 = np.concatenate(corrigido_11)\n",
    "    corrigido_merged_digital_11 = [1 if bit > 0.5 else 0 for bit in corrigido_merged_11]\n",
    "    calculated_ber_11 = np.sum(np.array(corrigido_merged_digital_11).astype(int) != merged_sample_11.astype(int)) / len(merged_sample_11)\n",
    "    ber_autoencoder_11.append(calculated_ber_11)\n",
    "    print('SNR ', Eb_dB_values[i], 'BER ', calculated_ber_11)\n",
    "    \n",
    "    ####################### Hamming code\n",
    "    # Merge sample to encode\n",
    "    split_encoded_data, split_original_data, merged_encoded_data = HammingCode.encode_sample(testing_data_hamming)\n",
    "\n",
    "    # Add noise\n",
    "    merged_encoded_data = [1.0 if bit == 1 else -1.0 for bit in merged_encoded_data]\n",
    "    merged_noise = np.concatenate(noise_hamming)\n",
    "    merged_encoded_data = merged_encoded_data + np.array(merged_noise)\n",
    "    digital_encoded_noisy = np.array([1 if x > 0 else 0.0 for x in merged_encoded_data])\n",
    "    \n",
    "    split_digital_encoded_noisy = np.array_split(digital_encoded_noisy, int(len(digital_encoded_noisy)/7))\n",
    "    \n",
    "    decoded_sample = HammingCode.decode_sample(split_digital_encoded_noisy)\n",
    "    calculated_ber_Hamming = np.sum(np.array(decoded_sample).astype(int) != testing_data_hamming.astype(int)) / len(testing_data_hamming)\n",
    "    ber_Hamming.append(calculated_ber_Hamming)\n",
    "    \n",
    "    print('SNR ', Eb_dB_values[i], 'BER ', calculated_ber_Hamming)    \n",
    "    \n",
    "    ####################### MLP\n",
    "    noise_smaller = noise_mlp[:, :4]\n",
    "    amostra_ruidosa = testing_data_mlp + noise_smaller\n",
    "    \n",
    "    mlp_corrigido = mlp.predict(amostra_ruidosa)\n",
    "    \n",
    "    mlp_corrigido_merged = np.concatenate(mlp_corrigido)\n",
    "    mlp_corrigido_merged_digital = [1 if bit > 0.5 else 0 for bit in mlp_corrigido_merged]\n",
    "    calculated_ber_mlp = np.sum(np.array(mlp_corrigido_merged_digital).astype(int) != merged_testing_data_mlp.astype(int)) / len(merged_testing_data_mlp)\n",
    "    ber_mlp.append(calculated_ber_mlp)\n",
    "    print('SNR ', Eb_dB_values[i], 'BER ', calculated_ber_mlp)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-06-10T23:26:01.389363400Z"
    }
   },
   "id": "f4df4b5fbca6afee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Eb_values_BPSK = 10**(Eb_dB_values/10)\n",
    "BPSK = [0.5 * erfc(np.sqrt(each)) for each in Eb_values_BPSK]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a57a56e0f3a67d4f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.semilogy(Eb_dB_values, ber_Hamming, marker='', linestyle='--', label='Codificado')\n",
    "plt.semilogy(Eb_dB_values, ber_mlp, marker='', linestyle='--', label='MLP')\n",
    "\n",
    "plt.semilogy(Eb_dB_values, ber_autoencoder, marker='', linestyle='--', label='Autoencoder')\n",
    "plt.semilogy(Eb_dB_values, ber_autoencoder_11, marker='', linestyle='--', label='Autoencoder 11 bits')\n",
    "\n",
    "plt.semilogy(Eb_dB_values, BPSK, marker='', linestyle='--', label='BPSK')\n",
    "plt.xlabel('Eb/No (dB)')\n",
    "plt.ylabel('BER')\n",
    "plt.grid(True, which='both')\n",
    "plt.legend()\n",
    "plt.title('BER x Eb/No')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fd84ba486377ddf5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7f12509ad54bf376",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
